{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "* Detect the text on the actual image.\n",
    "* Detect the text on the white background image.\n",
    "* Check if there is size difference.\n",
    "* Make the bounding boxes the same size by expanding the smaller one.\n",
    "* Than find the mapping function according to the actual image canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/07/05 15:33:04] ppocr DEBUG: Namespace(alpha=1.0, benchmark=False, beta=1.0, cls_batch_num=6, cls_image_shape='3, 48, 192', cls_model_dir='/Users/busraasan/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_thresh=0.9, cpu_threads=10, crop_res_save_dir='./output', det=True, det_algorithm='DB', det_box_type='quad', det_db_box_thresh=0.6, det_db_score_mode='fast', det_db_thresh=0.3, det_db_unclip_ratio=1.5, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_limit_side_len=960, det_limit_type='max', det_model_dir='/Users/busraasan/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, det_pse_thresh=0, det_sast_nms_thresh=0.2, det_sast_score_thresh=0.5, draw_img_save_dir='./inference_results', drop_score=0.5, e2e_algorithm='PGNet', e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_limit_side_len=768, e2e_limit_type='max', e2e_model_dir=None, e2e_pgnet_mode='fast', e2e_pgnet_score_thresh=0.5, e2e_pgnet_valid_set='totaltext', enable_mkldnn=False, fourier_degree=5, gpu_mem=500, help='==SUPPRESS==', image_dir=None, image_orientation=False, ir_optim=True, kie_algorithm='LayoutXLM', label_list=['0', '180'], lang='en', layout=True, layout_dict_path=None, layout_model_dir=None, layout_nms_threshold=0.5, layout_score_threshold=0.5, max_batch_size=10, max_text_length=25, merge_no_span_structure=True, min_subgraph_size=15, mode='structure', ocr=True, ocr_order_method=None, ocr_version='PP-OCRv3', output='./output', page_num=0, precision='fp32', process_id=0, re_model_dir=None, rec=True, rec_algorithm='SVTR_LCNet', rec_batch_num=6, rec_char_dict_path='/Users/busraasan/miniconda3/envs/causalml-py38/lib/python3.8/site-packages/paddleocr/ppocr/utils/en_dict.txt', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_model_dir='/Users/busraasan/.paddleocr/whl/rec/en/en_PP-OCRv3_rec_infer', recovery=False, save_crop_res=False, save_log_path='./log_output/', scales=[8, 16, 32], ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ser_model_dir=None, show_log=True, sr_batch_num=1, sr_image_shape='3, 32, 128', sr_model_dir=None, structure_version='PP-StructureV2', table=True, table_algorithm='TableAttn', table_char_dict_path=None, table_max_len=488, table_model_dir=None, total_process_num=1, type='ocr', use_angle_cls=True, use_dilation=False, use_gpu=False, use_mp=False, use_npu=False, use_onnx=False, use_pdf2docx_api=False, use_pdserving=False, use_space_char=True, use_tensorrt=False, use_visual_backbone=True, use_xpu=False, vis_font_path='./doc/fonts/simfang.ttf', warmup=False)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import os\n",
    "from utils import *\n",
    "\n",
    "from paddleocr import PaddleOCR,draw_ocr\n",
    "\n",
    "from PIL import Image, ImageFont\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from matplotlib.colors import hsv_to_rgb, rgb_to_hsv\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "# Paddleocr supports Chinese, English, French, German, Korean and Japanese.\n",
    "# You can set the parameter `lang` as `ch`, `en`, `fr`, `german`, `korean`, `japan`\n",
    "# to switch the language model in order.\n",
    "def compose_paragraphs(text_bboxes, text_palettes):\n",
    "\n",
    "        '''\n",
    "            Compose text data into paragraphs.\n",
    "            Return: Grouped indices of detected text elements.\n",
    "        '''\n",
    "        num_text_boxes = len(text_palettes)\n",
    "        print(num_text_boxes)\n",
    "        composed_text_idxs = [[0]]\n",
    "        for i in range(num_text_boxes-1):\n",
    "            palette1 = text_palettes[i]\n",
    "            palette2 = text_palettes[i+1]\n",
    "            if np.array_equal(palette1, palette2):\n",
    "                bbox1 = text_bboxes[i]\n",
    "                bbox2 = text_bboxes[i+1]\n",
    "                height1 = bbox1[0][1] - bbox1[3][1]\n",
    "                height2 = bbox2[0][1] - bbox2[3][1]\n",
    "                if abs(bbox1[0][1]-bbox2[0][1]) <= abs(height1)+30:\n",
    "                    if i != 0 and i not in composed_text_idxs[-1]:\n",
    "                        composed_text_idxs.append([i])\n",
    "                    composed_text_idxs[-1].append(i+1)\n",
    "                else:\n",
    "                    if i != 0 and i not in composed_text_idxs[-1] and [i] not in composed_text_idxs:\n",
    "                        composed_text_idxs.append([i])\n",
    "                    if i == num_text_boxes-2:\n",
    "                        composed_text_idxs.append([i+1])\n",
    "            else:\n",
    "                if i != 0 and i not in composed_text_idxs[-1]:\n",
    "                    composed_text_idxs.append([i])\n",
    "                if i == (num_text_boxes-2):\n",
    "                    composed_text_idxs.append([i+1])\n",
    "        return composed_text_idxs\n",
    "\n",
    "def merge_bounding_boxes(composed_text_idxs, bboxes):\n",
    "        '''\n",
    "            openCV --> x: left-to-right, y: top--to-bottom\n",
    "            bbox coordinates --> [[256.0, 1105.0], [1027.0, 1105.0], [1027.0, 1142.0], [256.0, 1142.0]]\n",
    "                             --> left top, right top, right bottom, left bottom\n",
    "\n",
    "            TODO: Also return color palettes for each merged box.\n",
    "        '''\n",
    "        \n",
    "        biggest_borders = []\n",
    "        for idxs in composed_text_idxs:\n",
    "            smallest_x = smallest_y = 10000\n",
    "            biggest_y = biggest_x = 0\n",
    "            if len(idxs) > 1:\n",
    "                for idx in idxs:\n",
    "                    bbox = bboxes[idx]\n",
    "                    bbox_smallest_x, bbox_smallest_y = np.min(bbox, axis=0)\n",
    "                    bbox_biggest_x, bbox_biggest_y = np.max(bbox, axis=0)\n",
    "\n",
    "                    if smallest_x > bbox_smallest_x:\n",
    "                        smallest_x = bbox_smallest_x\n",
    "                    if smallest_y > bbox_smallest_y:\n",
    "                        smallest_y = bbox_smallest_y\n",
    "                    if biggest_x < bbox_biggest_x:\n",
    "                        biggest_x = bbox_biggest_x\n",
    "                    if biggest_y < bbox_biggest_y:\n",
    "                        biggest_y =  bbox_biggest_y\n",
    "\n",
    "                biggest_border = [[smallest_x, smallest_y], [biggest_x, smallest_y], [biggest_x, biggest_y], [smallest_x, biggest_y]]\n",
    "                biggest_borders.append(biggest_border)\n",
    "            else:\n",
    "                biggest_borders.append(bboxes[idxs[0]])\n",
    "        return biggest_borders\n",
    "\n",
    "def extract_text_bbox(ocr, img_path, preview_image_path):\n",
    "        '''\n",
    "            Input: path to the text image\n",
    "            Extract text using paddleOCR.\n",
    "            Crop text from bounding box.\n",
    "            Extract colors using Kmeans inside the bbox.\n",
    "            Return the dominant color and the position.\n",
    "            \n",
    "            DONE: Try to combine very close lines as paragraph bbox. \n",
    "            If the the distance between two bbox is smaller than the bbox height and color is the same,\n",
    "            we can group them as paragraphs.\n",
    "\n",
    "            TODO: Cut images automatically from the sides by a margin.\n",
    "            When constructing bounding boxes, add these margins back to the coordinates.\n",
    "            Sometimes texts are extremely small that the model cannot detect.\n",
    "\n",
    "            Return: text color palettes, dominant colors for each text and position list (as bboxes).\n",
    "        '''\n",
    "        # Parameters for KMeans.\n",
    "        n_colors = 3\n",
    "\n",
    "        result = ocr.ocr(img_path, cls=True)[0]\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        boxes = [line[0] for line in result]\n",
    "        texts = [line[1][0] for line in result]\n",
    "        image = cv2.imread(img_path)\n",
    "        preview_image = cv2.imread(preview_image_path)\n",
    "\n",
    "        palettes = []\n",
    "        dominants = []\n",
    "        new_bboxes = []\n",
    "\n",
    "        # Run KMeans for each text object\n",
    "        for bbox in boxes:\n",
    "            # Crop the text area\n",
    "            x, y = int(bbox[0][0]), int(bbox[0][1])\n",
    "            z, t = int(bbox[2][0]), int(bbox[2][1])\n",
    "            cropped_image = image[y:t, x:z]\n",
    "\n",
    "            # Do template matching to find the places at the actual image because not every image has the same size.\n",
    "            method = cv2.TM_SQDIFF_NORMED\n",
    "            result = cv2.matchTemplate(cropped_image, preview_image, method)\n",
    "            mn,_,mnLoc,_ = cv2.minMaxLoc(result)\n",
    "            MPx,MPy = mnLoc\n",
    "            trows,tcols = cropped_image.shape[:2]\n",
    "            # --> left top, right top, right bottom, left bottom\n",
    "            bbox = [[MPx,MPy], [MPx+tcols, MPy], [MPx+tcols, MPy+trows], [MPx, MPy+trows]]\n",
    "\n",
    "            # Apply KMeans to the text area\n",
    "            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, .1)\n",
    "            flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "\n",
    "            pixels = np.float32(cropped_image.reshape(-1, 3))\n",
    "            _, labels, palette = cv2.kmeans(pixels, n_colors, None, criteria, 10, flags)\n",
    "            palette = np.asarray(palette, dtype=np.int64)\n",
    "            palette_w_white = []\n",
    "\n",
    "            for i, color in enumerate(palette):\n",
    "                x, y, z = color\n",
    "                # Do not add white to the palette since it is the same background in every pic.\n",
    "                if not (252 < x < 256 and 252 < y < 256 and 252 < z < 256):\n",
    "                    palette_w_white.append(color)\n",
    "                else:\n",
    "                    labels = np.delete(labels, np.where(labels == i))\n",
    "\n",
    "            _, counts = np.unique(labels, return_counts=True)\n",
    "            dominant = palette_w_white[np.argmax(counts)]\n",
    "            palettes.append(palette_w_white)\n",
    "            dominants.append(dominant)\n",
    "            new_bboxes.append(bbox)\n",
    "\n",
    "        return palettes, dominants, boxes, texts\n",
    "        \n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def extract_text_directly(ocr, img_path, white_bg_texts):\n",
    "    n_colors = 3\n",
    "\n",
    "    result = ocr.ocr(img_path, cls=True)[0]\n",
    "\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    boxes = [line[0] for line in result]\n",
    "    texts = [line[1][0].replace(\" \", \"\") for line in result]\n",
    "    white_bg_texts = [elem.replace(\" \", \"\") for elem in white_bg_texts]\n",
    "    image = cv2.imread(img_path)\n",
    "    same_idxs = []\n",
    "    new_boxes = []\n",
    "    \n",
    "    for elem in white_bg_texts:\n",
    "        for i, text in enumerate(texts):\n",
    "            if similar(elem, text) > 0.85:\n",
    "                new_boxes.append(boxes[i])\n",
    "\n",
    "    for bbox in new_boxes:\n",
    "        x, y = int(bbox[0][0]), int(bbox[0][1])\n",
    "        z, t = int(bbox[2][0]), int(bbox[2][1])\n",
    "        cropped_image = image[y:t, x:z]\n",
    "\n",
    "    return new_boxes\n",
    "\n",
    "def extract_decor_elements(decoration_path, preview_path):\n",
    "        # Determine the number of dominant colors\n",
    "        num_colors = 6\n",
    "        \n",
    "        # Load the image\n",
    "        image = cv2.imread(decoration_path)\n",
    "        preview_image = cv2.imread(preview_path)\n",
    "        \n",
    "        # Convert the image to the RGB color space\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image2 = image.copy()\n",
    "        \n",
    "        # Reshape the image to a 2D array of pixels\n",
    "        pixels = image.reshape(-1, 3)\n",
    "        \n",
    "        # Apply K-means clustering with the determined number of colors\n",
    "        kmeans = KMeans(n_clusters=num_colors)\n",
    "        kmeans.fit(pixels)\n",
    "        \n",
    "        # Get the RGB values of the dominant colors\n",
    "        colors = kmeans.cluster_centers_.astype(int)\n",
    "        print(\"Num of colors: \", len(colors))\n",
    "        \n",
    "        # Convert the colors to the HSV color space\n",
    "        hsv_colors = [] \n",
    "\n",
    "        for i, color in enumerate(colors):\n",
    "            x, y, z = color\n",
    "            if not (252 < x < 256 and 252 < y < 256 and 252 < z < 256):\n",
    "                x, y, z = rgb_to_hsv([x/255, y/255, z/255])\n",
    "                hsv_colors.append([x*180, y*255, z*255])\n",
    "        # Convert the image to the HSV color space\n",
    "        hsv_image = cv2.cvtColor(image2, cv2.COLOR_RGB2HSV)\n",
    "        \n",
    "        # Create masks for each dominant color\n",
    "        masks = []\n",
    "        hsv_colors = np.asarray(hsv_colors, dtype=np.int32)\n",
    "        \n",
    "        colors = []\n",
    "        for i in range(len(hsv_colors)):\n",
    "            \n",
    "            h, s, v = hsv_colors[i, :]\n",
    "            lower_color = hsv_colors[i, :] - np.array([10, 50, 50])\n",
    "            upper_color = hsv_colors[i, :] + np.array([10, 255, 255])\n",
    "            mask = cv2.inRange(hsv_image, lower_color, upper_color)\n",
    "            colors.append([h,s,v])\n",
    "            masks.append(mask)\n",
    "        \n",
    "        # Find contours in each mask\n",
    "        contours = []\n",
    "        for mask in masks:\n",
    "            contours_color, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            contours.append(contours_color)\n",
    "        \n",
    "        # Draw bounding boxes around the shapes\n",
    "        image_with_boxes = image.copy()\n",
    "        bboxes = []\n",
    "        for i, contour_color in enumerate(contours):\n",
    "            for contour in contour_color:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                # left top, right top, right bottom, left bottom\n",
    "                bboxes.append([[x,y], [x+w, y], [x+w, y+h], [x,y+h]])\n",
    "\n",
    "        new_bboxes = NMS(np.asarray(bboxes))\n",
    "        correct_bboxes = []\n",
    "        border_size=1\n",
    "        for bbox in new_bboxes:\n",
    "            [[x,y], [z, y], [z, t], [x, t]] = bbox\n",
    "            #cv2.rectangle(image_with_boxes, (x, y), (z, t), (0, 255, 0), 2)\n",
    "            cropped_image = image[y:t, x:z]\n",
    "            cropped_image = cv2.copyMakeBorder(\n",
    "                cropped_image,\n",
    "                top=border_size,\n",
    "                bottom=border_size,\n",
    "                left=border_size,\n",
    "                right=border_size,\n",
    "                borderType=cv2.BORDER_CONSTANT,\n",
    "                value=[255, 255, 255]\n",
    "            )\n",
    "\n",
    "            method = cv2.TM_SQDIFF_NORMED\n",
    "            result = cv2.matchTemplate(cropped_image, preview_image, method)\n",
    "            mn,_,mnLoc,_ = cv2.minMaxLoc(result)\n",
    "            MPx,MPy = mnLoc\n",
    "            trows,tcols = cropped_image.shape[:2]\n",
    "            bbox = [[MPx+1,MPy-1], [MPx+tcols+1,MPy-1], [MPx+tcols+1, MPy+trows-1], [MPx+1, MPy+trows-1]]\n",
    "            correct_bboxes.append(bbox)\n",
    "        \n",
    "        return colors, bboxes\n",
    "\n",
    "def map_decoration_coordinates(design_text_coordinate, text_coordinate, decoration_coordinates, prev_size, text_size):\n",
    "    # --> [[256.0, 1105.0], [1027.0, 1105.0], [1027.0, 1142.0], [256.0, 1142.0]]\n",
    "    # --> left top, right top, right bottom, left bottom\n",
    "\n",
    "    prev_x, prev_y = prev_size\n",
    "    print(prev_size, text_size)\n",
    "    text_x, text_y = text_size\n",
    "\n",
    "    design_x, design_y = design_text_coordinate[0]\n",
    "    text_x, text_y = text_coordinate[0]\n",
    "    print(\"TEXT X\")\n",
    "    print(text_x)\n",
    "    print(\"DESIGN X\")\n",
    "    print(design_x)\n",
    "\n",
    "    diff_x = text_x - design_x\n",
    "    diff_y = text_y - design_y\n",
    "    \n",
    "    new_coordinates = []\n",
    "    for coordinate in decoration_coordinates:\n",
    "        new_coor = []\n",
    "        for elem in coordinate:\n",
    "            print(\"ELEM X\")\n",
    "            print(elem[0])\n",
    "            new_coor.append([elem[0]-diff_x, elem[1]-diff_y])\n",
    "        new_coordinates.append(new_coor)\n",
    "\n",
    "    return new_coordinates\n",
    "\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en') # need to run only once to download and load model into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/07/05 15:33:07] ppocr DEBUG: dt_boxes num : 7, elapse : 0.9603531360626221\n",
      "[2023/07/05 15:33:07] ppocr DEBUG: cls num  : 7, elapse : 0.08154010772705078\n",
      "[2023/07/05 15:33:09] ppocr DEBUG: rec_res num  : 7, elapse : 1.3612589836120605\n",
      "7\n",
      "[2023/07/05 15:33:10] ppocr DEBUG: dt_boxes num : 9, elapse : 0.4151937961578369\n",
      "[2023/07/05 15:33:11] ppocr DEBUG: cls num  : 9, elapse : 0.0915839672088623\n",
      "[2023/07/05 15:33:12] ppocr DEBUG: rec_res num  : 9, elapse : 1.6123747825622559\n",
      "7\n",
      "Num of colors:  6\n",
      "(1902, 1068) (3188, 3596)\n",
      "TEXT X\n",
      "989.0\n",
      "DESIGN X\n",
      "124.0\n",
      "ELEM X\n",
      "1821\n",
      "ELEM X\n",
      "1910\n",
      "ELEM X\n",
      "1910\n",
      "ELEM X\n",
      "1821\n",
      "ELEM X\n",
      "895\n",
      "ELEM X\n",
      "1071\n",
      "ELEM X\n",
      "1071\n",
      "ELEM X\n",
      "895\n",
      "ELEM X\n",
      "1748\n",
      "ELEM X\n",
      "1910\n",
      "ELEM X\n",
      "1910\n",
      "ELEM X\n",
      "1748\n",
      "ELEM X\n",
      "1366\n",
      "ELEM X\n",
      "1425\n",
      "ELEM X\n",
      "1425\n",
      "ELEM X\n",
      "1366\n",
      "ELEM X\n",
      "1366\n",
      "ELEM X\n",
      "1425\n",
      "ELEM X\n",
      "1425\n",
      "ELEM X\n",
      "1366\n",
      "ELEM X\n",
      "855\n",
      "ELEM X\n",
      "931\n",
      "ELEM X\n",
      "931\n",
      "ELEM X\n",
      "855\n",
      "ELEM X\n",
      "855\n",
      "ELEM X\n",
      "931\n",
      "ELEM X\n",
      "931\n",
      "ELEM X\n",
      "855\n",
      "ELEM X\n",
      "1913\n",
      "ELEM X\n",
      "1935\n",
      "ELEM X\n",
      "1935\n",
      "ELEM X\n",
      "1913\n",
      "ELEM X\n",
      "855\n",
      "ELEM X\n",
      "923\n",
      "ELEM X\n",
      "923\n",
      "ELEM X\n",
      "855\n",
      "ELEM X\n",
      "1877\n",
      "ELEM X\n",
      "1935\n",
      "ELEM X\n",
      "1935\n",
      "ELEM X\n",
      "1877\n",
      "ELEM X\n",
      "1598\n",
      "ELEM X\n",
      "1739\n",
      "ELEM X\n",
      "1739\n",
      "ELEM X\n",
      "1598\n",
      "ELEM X\n",
      "1003\n",
      "ELEM X\n",
      "1145\n",
      "ELEM X\n",
      "1145\n",
      "ELEM X\n",
      "1003\n",
      "ELEM X\n",
      "1850\n",
      "ELEM X\n",
      "1866\n",
      "ELEM X\n",
      "1866\n",
      "ELEM X\n",
      "1850\n",
      "ELEM X\n",
      "981\n",
      "ELEM X\n",
      "998\n",
      "ELEM X\n",
      "998\n",
      "ELEM X\n",
      "981\n",
      "ELEM X\n",
      "1033\n",
      "ELEM X\n",
      "1049\n",
      "ELEM X\n",
      "1049\n",
      "ELEM X\n",
      "1033\n",
      "ELEM X\n",
      "1866\n",
      "ELEM X\n",
      "1910\n",
      "ELEM X\n",
      "1910\n",
      "ELEM X\n",
      "1866\n",
      "ELEM X\n",
      "1366\n",
      "ELEM X\n",
      "1425\n",
      "ELEM X\n",
      "1425\n",
      "ELEM X\n",
      "1366\n",
      "ELEM X\n",
      "1366\n",
      "ELEM X\n",
      "1425\n",
      "ELEM X\n",
      "1425\n",
      "ELEM X\n",
      "1366\n",
      "ELEM X\n",
      "855\n",
      "ELEM X\n",
      "1257\n",
      "ELEM X\n",
      "1257\n",
      "ELEM X\n",
      "855\n",
      "ELEM X\n",
      "1597\n",
      "ELEM X\n",
      "1935\n",
      "ELEM X\n",
      "1935\n",
      "ELEM X\n",
      "1597\n",
      "ELEM X\n",
      "1598\n",
      "ELEM X\n",
      "1739\n",
      "ELEM X\n",
      "1739\n",
      "ELEM X\n",
      "1598\n",
      "ELEM X\n",
      "1003\n",
      "ELEM X\n",
      "1145\n",
      "ELEM X\n",
      "1145\n",
      "ELEM X\n",
      "1003\n",
      "ELEM X\n",
      "1850\n",
      "ELEM X\n",
      "1866\n",
      "ELEM X\n",
      "1866\n",
      "ELEM X\n",
      "1850\n",
      "ELEM X\n",
      "981\n",
      "ELEM X\n",
      "998\n",
      "ELEM X\n",
      "998\n",
      "ELEM X\n",
      "981\n",
      "ELEM X\n",
      "1033\n",
      "ELEM X\n",
      "1049\n",
      "ELEM X\n",
      "1049\n",
      "ELEM X\n",
      "1033\n",
      "ELEM X\n",
      "1866\n",
      "ELEM X\n",
      "1910\n",
      "ELEM X\n",
      "1910\n",
      "ELEM X\n",
      "1866\n",
      "ELEM X\n",
      "906\n",
      "ELEM X\n",
      "937\n",
      "ELEM X\n",
      "937\n",
      "ELEM X\n",
      "906\n",
      "ELEM X\n",
      "994\n",
      "ELEM X\n",
      "1061\n",
      "ELEM X\n",
      "1061\n",
      "ELEM X\n",
      "994\n",
      "ELEM X\n",
      "1821\n",
      "ELEM X\n",
      "1910\n",
      "ELEM X\n",
      "1910\n",
      "ELEM X\n",
      "1821\n",
      "ELEM X\n",
      "895\n",
      "ELEM X\n",
      "1071\n",
      "ELEM X\n",
      "1071\n",
      "ELEM X\n",
      "895\n",
      "ELEM X\n",
      "1748\n",
      "ELEM X\n",
      "1910\n",
      "ELEM X\n",
      "1910\n",
      "ELEM X\n",
      "1748\n",
      "ELEM X\n",
      "1366\n",
      "ELEM X\n",
      "1425\n",
      "ELEM X\n",
      "1425\n",
      "ELEM X\n",
      "1366\n",
      "ELEM X\n",
      "1366\n",
      "ELEM X\n",
      "1425\n",
      "ELEM X\n",
      "1425\n",
      "ELEM X\n",
      "1366\n",
      "ELEM X\n",
      "855\n",
      "ELEM X\n",
      "931\n",
      "ELEM X\n",
      "931\n",
      "ELEM X\n",
      "855\n",
      "ELEM X\n",
      "855\n",
      "ELEM X\n",
      "931\n",
      "ELEM X\n",
      "931\n",
      "ELEM X\n",
      "855\n",
      "ELEM X\n",
      "1912\n",
      "ELEM X\n",
      "1935\n",
      "ELEM X\n",
      "1935\n",
      "ELEM X\n",
      "1912\n",
      "ELEM X\n",
      "855\n",
      "ELEM X\n",
      "924\n",
      "ELEM X\n",
      "924\n",
      "ELEM X\n",
      "855\n",
      "ELEM X\n",
      "1877\n",
      "ELEM X\n",
      "1935\n",
      "ELEM X\n",
      "1935\n",
      "ELEM X\n",
      "1877\n",
      "ELEM X\n",
      "1598\n",
      "ELEM X\n",
      "1739\n",
      "ELEM X\n",
      "1739\n",
      "ELEM X\n",
      "1598\n",
      "ELEM X\n",
      "1003\n",
      "ELEM X\n",
      "1145\n",
      "ELEM X\n",
      "1145\n",
      "ELEM X\n",
      "1003\n",
      "ELEM X\n",
      "1850\n",
      "ELEM X\n",
      "1866\n",
      "ELEM X\n",
      "1866\n",
      "ELEM X\n",
      "1850\n",
      "ELEM X\n",
      "869\n",
      "ELEM X\n",
      "955\n",
      "ELEM X\n",
      "955\n",
      "ELEM X\n",
      "869\n",
      "ELEM X\n",
      "1798\n",
      "ELEM X\n",
      "1897\n",
      "ELEM X\n",
      "1897\n",
      "ELEM X\n",
      "1798\n",
      "ELEM X\n",
      "981\n",
      "ELEM X\n",
      "998\n",
      "ELEM X\n",
      "998\n",
      "ELEM X\n",
      "981\n",
      "ELEM X\n",
      "872\n",
      "ELEM X\n",
      "944\n",
      "ELEM X\n",
      "944\n",
      "ELEM X\n",
      "872\n",
      "ELEM X\n",
      "1033\n",
      "ELEM X\n",
      "1049\n",
      "ELEM X\n",
      "1049\n",
      "ELEM X\n",
      "1033\n",
      "ELEM X\n",
      "1866\n",
      "ELEM X\n",
      "1910\n",
      "ELEM X\n",
      "1910\n",
      "ELEM X\n",
      "1866\n",
      "ELEM X\n",
      "1707\n",
      "ELEM X\n",
      "1735\n",
      "ELEM X\n",
      "1735\n",
      "ELEM X\n",
      "1707\n",
      "ELEM X\n",
      "1749\n",
      "ELEM X\n",
      "1790\n",
      "ELEM X\n",
      "1790\n",
      "ELEM X\n",
      "1749\n",
      "ELEM X\n",
      "906\n",
      "ELEM X\n",
      "937\n",
      "ELEM X\n",
      "937\n",
      "ELEM X\n",
      "906\n",
      "ELEM X\n",
      "994\n",
      "ELEM X\n",
      "1061\n",
      "ELEM X\n",
      "1061\n",
      "ELEM X\n",
      "994\n",
      "[[[956.0, 1832.0], [1045.0, 1832.0], [1045.0, 1894.0], [956.0, 1894.0]], [[30.0, 1727.0], [206.0, 1727.0], [206.0, 1885.0], [30.0, 1885.0]], [[883.0, 1712.0], [1045.0, 1712.0], [1045.0, 1859.0], [883.0, 1859.0]], [[501.0, 1453.0], [560.0, 1453.0], [560.0, 1488.0], [501.0, 1488.0]], [[501.0, 1426.0], [560.0, 1426.0], [560.0, 1461.0], [501.0, 1461.0]], [[-10.0, 1309.0], [66.0, 1309.0], [66.0, 1342.0], [-10.0, 1342.0]], [[-10.0, 1242.0], [66.0, 1242.0], [66.0, 1309.0], [-10.0, 1309.0]], [[1048.0, 1229.0], [1070.0, 1229.0], [1070.0, 1274.0], [1048.0, 1274.0]], [[-10.0, 1213.0], [58.0, 1213.0], [58.0, 1227.0], [-10.0, 1227.0]], [[1012.0, 1192.0], [1070.0, 1192.0], [1070.0, 1307.0], [1012.0, 1307.0]], [[733.0, 1107.0], [874.0, 1107.0], [874.0, 1142.0], [733.0, 1142.0]], [[138.0, 1102.0], [280.0, 1102.0], [280.0, 1136.0], [138.0, 1136.0]], [[985.0, 637.0], [1001.0, 637.0], [1001.0, 710.0], [985.0, 710.0]], [[116.0, 529.0], [133.0, 529.0], [133.0, 602.0], [116.0, 602.0]], [[168.0, 492.0], [184.0, 492.0], [184.0, 534.0], [168.0, 534.0]], [[1001.0, 479.0], [1045.0, 479.0], [1045.0, 536.0], [1001.0, 536.0]], [[501.0, 1453.0], [560.0, 1453.0], [560.0, 1488.0], [501.0, 1488.0]], [[501.0, 1426.0], [560.0, 1426.0], [560.0, 1461.0], [501.0, 1461.0]], [[-10.0, 1155.0], [392.0, 1155.0], [392.0, 1908.0], [-10.0, 1908.0]], [[732.0, 1128.0], [1070.0, 1128.0], [1070.0, 1908.0], [732.0, 1908.0]], [[733.0, 1107.0], [874.0, 1107.0], [874.0, 1142.0], [733.0, 1142.0]], [[138.0, 1102.0], [280.0, 1102.0], [280.0, 1136.0], [138.0, 1136.0]], [[985.0, 637.0], [1001.0, 637.0], [1001.0, 710.0], [985.0, 710.0]], [[116.0, 529.0], [133.0, 529.0], [133.0, 602.0], [116.0, 602.0]], [[168.0, 492.0], [184.0, 492.0], [184.0, 534.0], [168.0, 534.0]], [[1001.0, 479.0], [1045.0, 479.0], [1045.0, 536.0], [1001.0, 536.0]], [[41.0, 455.0], [72.0, 455.0], [72.0, 477.0], [41.0, 477.0]], [[129.0, 436.0], [196.0, 436.0], [196.0, 478.0], [129.0, 478.0]], [[956.0, 1830.0], [1045.0, 1830.0], [1045.0, 1894.0], [956.0, 1894.0]], [[30.0, 1727.0], [206.0, 1727.0], [206.0, 1885.0], [30.0, 1885.0]], [[883.0, 1712.0], [1045.0, 1712.0], [1045.0, 1860.0], [883.0, 1860.0]], [[501.0, 1453.0], [560.0, 1453.0], [560.0, 1488.0], [501.0, 1488.0]], [[501.0, 1426.0], [560.0, 1426.0], [560.0, 1461.0], [501.0, 1461.0]], [[-10.0, 1305.0], [66.0, 1305.0], [66.0, 1342.0], [-10.0, 1342.0]], [[-10.0, 1241.0], [66.0, 1241.0], [66.0, 1309.0], [-10.0, 1309.0]], [[1047.0, 1229.0], [1070.0, 1229.0], [1070.0, 1275.0], [1047.0, 1275.0]], [[-10.0, 1213.0], [59.0, 1213.0], [59.0, 1227.0], [-10.0, 1227.0]], [[1012.0, 1192.0], [1070.0, 1192.0], [1070.0, 1308.0], [1012.0, 1308.0]], [[733.0, 1107.0], [874.0, 1107.0], [874.0, 1142.0], [733.0, 1142.0]], [[138.0, 1102.0], [280.0, 1102.0], [280.0, 1136.0], [138.0, 1136.0]], [[985.0, 637.0], [1001.0, 637.0], [1001.0, 710.0], [985.0, 710.0]], [[4.0, 572.0], [90.0, 572.0], [90.0, 622.0], [4.0, 622.0]], [[933.0, 564.0], [1032.0, 564.0], [1032.0, 605.0], [933.0, 605.0]], [[116.0, 529.0], [133.0, 529.0], [133.0, 602.0], [116.0, 602.0]], [[7.0, 497.0], [79.0, 497.0], [79.0, 519.0], [7.0, 519.0]], [[168.0, 492.0], [184.0, 492.0], [184.0, 534.0], [168.0, 534.0]], [[1001.0, 479.0], [1045.0, 479.0], [1045.0, 536.0], [1001.0, 536.0]], [[842.0, 600.0], [870.0, 600.0], [870.0, 638.0], [842.0, 638.0]], [[884.0, 545.0], [925.0, 545.0], [925.0, 571.0], [884.0, 571.0]], [[41.0, 455.0], [72.0, 455.0], [72.0, 477.0], [41.0, 477.0]], [[129.0, 436.0], [196.0, 436.0], [196.0, 478.0], [129.0, 478.0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DETECT TEXT ON TEXT IMAGE\n",
    "text = '../destijl_dataset/04_text/0007.png'\n",
    "preview = '../destijl_dataset/00_preview/0007.png'\n",
    "decoration = '../destijl_dataset/03_decoration/0007.png'\n",
    "image = cv2.imread(preview)\n",
    "image_text = cv2.imread(text)\n",
    "image2 = image.copy()\n",
    "\n",
    "text_palettes, text_dominants, text_bboxes, texts = extract_text_bbox(ocr, text, preview)\n",
    "composed_text_idxs = compose_paragraphs(text_bboxes, text_palettes)\n",
    "merged_bboxes = merge_bounding_boxes(composed_text_idxs, text_bboxes)\n",
    "\n",
    "# DETECT TEXT ON REAL DESIGN\n",
    "image = cv2.imread(preview)\n",
    "image2 = image.copy()\n",
    "image3 = image.copy()\n",
    "\n",
    "text_bboxes1 = extract_text_directly(ocr, preview, texts)\n",
    "composed_text_idxs1 = compose_paragraphs(text_bboxes1, text_palettes)\n",
    "merged_bboxes1 = merge_bounding_boxes(composed_text_idxs1, text_bboxes1)\n",
    "decoration_hsv_palettes, decoration_bboxes = extract_decor_elements(decoration, preview)\n",
    "new_coordinates = map_decoration_coordinates(text_bboxes1[0], text_bboxes[0], decoration_bboxes, (image.shape[0], image.shape[1]), (image_text.shape[0], image_text.shape[1]))\n",
    "\n",
    "print(new_coordinates)\n",
    "# for bbox in text_bboxes1:\n",
    "#     x, y = bbox[0][0], bbox[0][1]\n",
    "#     z, t = bbox[2][0], bbox[2][1]\n",
    "#     cv2.rectangle(image, (int(x), int(y)), (int(z), int(t)), (0, 255, 0), 2)\n",
    "    \n",
    "# cv2.imwrite('result_prev.jpg', image)\n",
    "\n",
    "# for bbox in text_bboxes:\n",
    "#     x, y = bbox[0][0], bbox[0][1]\n",
    "#     z, t = bbox[2][0], bbox[2][1]\n",
    "#     cv2.rectangle(image2, (int(x), int(y)), (int(z), int(t)), (0, 255, 0), 2)\n",
    "    \n",
    "# cv2.imwrite('result_text.jpg', image2)\n",
    "\n",
    "for bbox in new_coordinates:\n",
    "    x, y = bbox[0][0], bbox[0][1]\n",
    "    z, t = bbox[2][0], bbox[2][1]\n",
    "    cv2.rectangle(image3, (int(x), int(y)), (int(z), int(t)), (0, 255, 0), 2)\n",
    "    \n",
    "cv2.imwrite('result_dec.jpg', image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('causalml-py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fe1114d0d27f71ad4119f0373fc1aaac921ee939a643d798102047e2deae920"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
